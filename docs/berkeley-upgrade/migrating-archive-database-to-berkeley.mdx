---
title: Migrating Mainnet Archive to Berkeley Archive 
sidebar_label: Archive migration
hide_title: true
description: Steps to properly migrate archives from Mainnet to Berkeley.
keywords:
  - Berkeley
  - upgrade
  - archive migration
  - planning 
  - prerequisites
  - mina archive node
  - archive node
---

# Mainnet to Berkeley Archive Migration

Before you start the migration, please read [How to prepare for archive migration](/berkeley-upgrade/planning-archive-migration).

## Download migration applications

Migration applications are distributed as part of the archive migration Docker and Debian packages.

Choose packages appropriate for your environment. 

The following commands help you install Debian packages or Docker images.

### Debian packages

```
CODENAME=bullseye
CHANNEL=unstable
# Berkeley nightly version
VERSION=2.0.0berkeley-rc1-berkeley-c308efc

echo "deb [trusted=yes] http://packages.o1test.net $CODENAME $CHANNEL" | tee /etc/apt/sources.list.d/mina.list
apt-get update
apt-get install --allow-downgrades -y "mina-archive-berkeley-archive-migration=$VERSION"
```

### Docker Image

To get the Docker image:


```
docker pull gcr.io/o1labs-192920/mina-archive-berkeley-archive-migration:1.0.0umt-tooling
```

## Mainnet Genesis Ledger

The Mina Mainnet genesis ledger is stored in GitHub in the `mina` repository under the `genesis_ledgers` subfolder. However, if you are already running a daemon that is connected to the Mina Mainnet network, you already have the genesis ledger locally.

## Berkeley database schema files

You can get the Berkeley schema files from different locations:

- GitHub repository under `berkeley` branch. 

    Note: The `berkeley` branch can contain new updates regarding schema files, so always get the latest schema files instead of using an already downloaded schema. 
- Archive/Rosetta Docker from `berkeley` version

### Example: Downloading schema sources from GitHub

   ```sh
   wget https://raw.githubusercontent.com/MinaProtocol/mina/berkeley/src/app/archive/zkapp_tables.sql

   wget https://raw.githubusercontent.com/MinaProtocol/mina/berkeley/src/app/archive/create_schema.sql

   ```

### Migration process

As mentioned in [Planning the Archive Migration](/berkeley-upgrade/planning-archive-migration), the mainnet migration can take up to a couple of days. 
Therefore, it is recommended to split migration into 3 stages:

- **Stage1:** Initial migration

- **Stage2:** Incremental migration

- **Stage3:** Remainder migration

Each stage has two migration phases:

- **Phase 1:** Copying data from mainnet database and precomputed blocks using the **berkeley_migration** app.

- **Phase 2:** Populating new berkeley tables using the **replayer app in migration mode**

Review these phases and stages before you start the migration:

#### Stage 1: Initial migration

This stage is the very first one, which requires the initial `berkeley` schema. It is a foundation for the next migration stage because it populates the migrated database and creates an initial checkpoint for further incremental migration.

- Inputs
   - Unmigrated mainnet database
   - Mainnet genesis ledger 
   - Empty `berkeley` schema 

- Outputs
   - Migrated `mainnet` database to the `berkeley` database from genesis up to the last canonical block
   - Replayer checkpoint, which can be used for incremental migration

##### Phase 1: Berkeley migration app run

```
mina-berkeley-migration --batch-size 1000 --config-file genesis_ledgers/mainnet.json
--mainnet-archive-uri {mainnet_connection_string} --migrated-archive-uri {migrated_connection_string} --mainnet-blocks-bucket 
{bucket name} --network "mainnet"
```
where: 
`--network` - precomputed blocks prefix 


##### Phase 2: Replayer in migration mode run

Replayer config must contain the Mainnet ledger as the starting point. So first, you must prepare the replayer config file:

```
 jq '.ledger.accounts' mainnet.json | jq  '{genesis_ledger: {accounts: .}}' > replayer_input_config.json"
```

Then:
```
 mina-replayer --migration-mode --archive-uri {migrated_connection_string}  --input-file replayer_input_config.json --checkpoint-interval 10000
```

#### Stage 2: Incremental migration

After the initial migration, the data is migrated data up to the last canonical block. However, `mainnet` data is progressing with new blocks that must also be migrated again and again until the fork block is announced. 


- Inputs
   - Newest mainnet database
   - Mainnet genesis ledger
   - Replayer checkpoint from last run 
   - Migrated berkeley schema from initial migration 

- Outputs
   - Migrated mainnet database to berkeley from up to last canonical block
   - Replayer checkpoint which can be used for next incremental migration

##### Phase 1: Berkeley migration app run

```
mina-berkeley-migration --batch-size 1000 --config-file genesis_ledgers/mainnet.json
--mainnet-archive-uri {mainnet_connection_string} --migrated-archive-uri {migrated_connection_string} --mainnet-blocks-bucket 
{bucket name} --network "mainnet"
```
where: 
`--network` - precomputed blocks prefix 


##### Phase 2: Replayer in migration mode run

```
 mina-replayer --migration-mode --archive-uri {migrated_connection_string}  --input-file replayer-checkpoint-XXXXX.json --checkpoint-interval 10000
```

where `replayer-checkpoint-XXXXX.json` - is last checkpoint generated from previous migration


Incremental migration can be run continuously on top initial migration or last incremental until fork block is anounced 

#### Stage 3: Remainder migration

When the fork block is announced, you must tackle the remainder migration. This is the last migration run 
you need to perform.

- Inputs
   - Newest mainnet database
   - Mainnet genesis ledger
   - Replayer checkpoint from last run 
   - Migrated berkeley schema from last run
   - Fork block state hash

- Outputs
   - Migrated mainnet database to berkeley from up fork point
   - Replayer checkpoint which can be used for replayer run on berkeley schema


##### Phase 1: Berkeley migration app run

You might notice a decrease in `batch-size` for precomputed blocks as the tool might hit missing precomputed blocks problem if you fetch too many of them in a single batch while trying to migrate the newest blocks in the chain:

```
mina-berkeley-migration --batch-size 2 --config-file genesis_ledgers/mainnet.json
--mainnet-archive-uri {mainnet_connection_string} --migrated-archive-uri {migrated_connection_string} --mainnet-blocks-bucket 
{bucket name} --network "mainnet" **--fork-state-hash {fork-state-hash}**
```
where: 
`--network` - precomputed blocks prefix 
`--fork-state-hash` last migrated block which will be used as a fork point 

**Info** When running the **berkeley-migration** app with fork-state-hash, there is no requirement for the fork state block to be canonical.
The tool automatically converts all pending blocks in the subchain, including the fork block, to canonical blocks.

##### Phase 2: Replayer in migration mode run

```
 mina-replayer --migration-mode --archive-uri {migrated_connection_string}  --input-file replayer-checkpoint-XXXXX.json --checkpoint-interval 10000 --output-file replayer_output.json 
```

where:
`replayer-checkpoint-XXXXX.json` - is last checkpoint generated from previous migration
`replayer-output.json` - will contain a very last checkpoint which can be used for berkeley replayer validation

It is important to save checkpoint which was dumped from replayer run, as it will be use in next migrations

### Example steps using Mina Foundation data

1. Download and import archive dump:

   ```sh
   wget -c https://storage.googleapis.com/mina-archive-dumps/mainnet-archive-dump-2023-11-02_0000.sql.tar.gz

   tar -xf mainnet-archive-dump-2023-11-02_0000.sql.tar.gz 

   psql -U postgres -a -f mainnet-archive-dump-2023-11-02_0000.sql
   ```

2. Download migration software:

   ```sh
   CODENAME=bullseye
   CHANNEL=unstable
   # Berkeley nightly version
   VERSION=2.0.0berkeley-rc1-berkeley-c308efc-bullseye

   echo "deb [trusted=yes] http://packages.o1test.net $CODENAME $CHANNEL" | tee /etc/apt/sources.list.d/mina.list
   apt-get update
   apt-get install --allow-downgrades -y "mina-archive-berkeley-archive-migration=$VERSION"
   ```

3. Create migrated schema:

   ```sh
   wget https://raw.githubusercontent.com/MinaProtocol/mina/berkeley/src/app/archive/zkapp_tables.sql

   wget https://raw.githubusercontent.com/MinaProtocol/mina/berkeley/src/app/archive/create_schema.sql

   psql  -U postgres -c "CREATE DATABASE berkeley_migrated;"

   psql -U postgres -d berkeley_migrated -a -f create_schema.sql"
   ```

4. Stage 1: Initial migration

   4.a) Phase 1:

   ```sh
   mina-berkeley-migration.exe --batch-size 2000 --config-file /etc/mina/genesis_ledgers/mainnet.json --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated --migrated-archive-uri postgres://postgres:postgres@localhost/berkeley_migrated --mainnet-blocks-bucket mina_network_block_data --network mainnet
   ```

   4.b) Phase 2:

   ```sh
   jq '.ledger.accounts' mainnet.json | jq  '{genesis_ledger: {accounts: .}}' > replayer_input_config.json"

   mina-replayer --migration-mode --archive-uri postgres://postgres:postgres@localhost/ --input-file replayer_config_input.json --checkpoint-interval 100  --checkpoint-file-prefix migration
   ```

5. Stage 2: Initial migration

   5.a) Phase 1:

   ```sh
   mina-berkeley-migration.exe --batch-size 2000 --config-file /etc/mina/genesis_ledgers/mainnet.json --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated --migrated-archive-uri postgres://postgres:postgres@localhost/berkeley_migrated --mainnet-blocks-bucket mina_network_block_data --network mainnet
   ```

   5.b) Phase 2:

   ```sh
   mina-replayer --migration-mode --archive-uri postgres://postgres:postgres@localhost/ --input-file checkpoint-XXXX.json --checkpoint-interval 100  --checkpoint-file-prefix migration
   ```

5. Stage 2: Remainder migration

   5.a) Phase 1:

   ```sh
   mina-berkeley-migration.exe --batch-size 2000 --config-file /etc/mina/genesis_ledgers/mainnet.json --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated --migrated-archive-uri postgres://postgres:postgres@localhost/berkeley_migrated --mainnet-blocks-bucket mina_network_block_data --network mainnet --fork-state-hash "3NLdCBNrDseiDKvVj8rZ15k2oAUvx4XuCc8mzf6fL2CmqTJVVceM" 
   ```

   :warning: 3NLdCBNrDseiDKvVj8rZ15k2oAUvx4XuCc8mzf6fL2CmqTJVVceM - is an example random hash, please **do not user this hash** on the actual migration. Use the official hash as provided by Mina Foundation for the fork point.

   5.b) Phase 2:

   ```sh
   mina-replayer --migration-mode --archive-uri postgres://postgres:postgres@localhost/ --input-file checkpoint-XXXX.json --checkpoint-interval 100  --checkpoint-file-prefix migration --output-file migrated-checkpoint-at-fork-block.json
   ```


## How to verify a successful migration

o1Labs and the Mina Foundation make every effort to provide reliable tools of high quality. However, it is not possible to eliminate all errors and test all possible Mainnet archives variations. 

Follow this checklist to perform major versification's after migration to ensure data correctness. 

1. #### The Replayer from the Mainnet version generates the same ledger hash as the migrated

Ensure that replayer from Mainnet and berkeley generate the same ledger for the migrated and the Mainnet database. 

- To verify, start the Mainnet replayer with the same input config as Berkeley. 

- When you run replayer from Mainnet version on Mainnet, archive it with the `--output-config` option to generate a reference replayer output that can be compared with the migrated replayer output.

2. #### All transaction (user command and internal command) hashes are left intact

Verify that the `user_command` and `internal_command` tables have the Mainnet format of hashes. For example, `CkpZirFuoLVV...`.

3. #### Parent-child block relationship is preserved

Verify that a given block in the migrated archive has the same parent in the Mainnet archive (`state_hash` and `parent_hash` columns).

4. #### Account balances remain the same

Verify the same balance exists for a given block in Mainnet and migrated databases.

## Notes on migration approach

We are aware that the migration process can be very long, (a couple of days). Therefore, we encourage using cron jobs that migrate data incrementally. The cron job requires access to Google Cloud buckets (or other storage):

- A bucket to store migrated-so-far database dumps
- A bucket to store checkpoint files

To prime the cron job, upload an initial database dump and an initial checkpoint file. 

To create the files, run these steps locally:

1. Download a Mainnet archive dump and load it into PostgreSQL.
2. Create a new, empty database using the new archive schema.
3. Run the berkeley-migration app against the Mainnet and new databases.
4. Run the replayer app in migration mode with the --checkpoint-interval set to some suitable value (perhaps 100) and start with the original Mainnet ledger in the input file.
5. Use pg_dump to dump the migrated database and upload it.
6. Upload the most recent checkpoint file.

The cron job performs the same steps in an automated fashion:

1. Pulls the latest Mainnet archive dump and loads it into PostgresQL.
2. Pulls the latest migrated database and loads it into PostgreSQL.
3. Pulls the latest checkpoint file.
4. Runs the berkeley-migration app against the two databases.
5. Runs the replayer app in migration mode using the downloaded checkpoint file; the checkpoint interval should be smaller (perhaps 50) because there are typically only 200 or so blocks in a day.
7. Uploads the migrated database.
8. Uploads the most recent checkpoint file.

Be sure to monitor the cron job in case there are errors.

Just before the Berkeley, migrate the last few blocks by running locally:

1. Download the Mainnet archive data directly from the k8s PostgreSQL node, not from the archive dump, and load it into PostgreSQL.
2. Download the most recent migrated database and load it into PostgresQL.
3. Download the most recent checkpoint file.
4. Run the berkeley-migration app against the two databases.
5. Run the replayer app in migration mode using the most recent checkpoint file.

It is worthwhile to perform these last steps as a dry run to make sure all goes well. You can run these steps as many times as needed.

### Known migration problems

#### Berkeley migration app is consuming all of my resources

When running a full migration, you can stumble on memory leaks that prevent you from cleanly performing the migration in one pass. A machine with 64 GB of RAM can be frozen after ~40k migrated blocks. Each 200 blocks inserted into the database increases the memory leak by 4â€“10 MB.

A potential workaround is to split migration into smaller parts using cron jobs or automation scripts.

Related Github issues:
- [#13714](https://github.com/MinaProtocol/mina/issues/13714)
- [#14924](https://github.com/MinaProtocol/mina/issues/14924)

## FAQ

#### Migrated database is missing orphaned blocks

By design, Berkeley migration omits orphaned blocks and, by default, migrates only canonical blocks.

#### Migrated database missing pending blocks

By design, the Berkeley migration app does not migrate pending blocks. If you want to migrate pending blocks, use the `--end-global-slot` parameter with the value of the requested slot. Ensure that pending blocks that exist on requested slots as archive node convert the old pending blocks to orphaned blocks.

#### Replayer in migration mode overrides my old checkpoints

Replayer by default dumps the checkpoint to the current folder. All checkpoint files have a similar format:

`replayer-checkpoint-{number}.json.`

To modify the output folder and prefix, you can use the `--checkpoint-output-folder` and `--checkpoint-file-prefix` parameters to prevent override of old checkpoints.

#### Receipt chain hashes mismatch between Mainnet and Berkeley schemas

Receipt chain hashes are expressed in a new format in the Berkeley version. They contain the same value, though.

#### Replayer in migration mode exits the process in the middle of the run

Most likely, there are some missing blocks in the Mainnet database. Ensure that you patched the Mainnet archive before the migration process. Alternatively, you can provide `--continue-on-error` parameter.

#### How to migrate Mainnet pending blocks

In the first phase of migration use the `--end-global-slot` parameter. 

In the second phase of migration, add property `target_epoch_ledgers_state_hash` with the expected `state_hash` value:

```json
{
   "target_epoch_ledgers_state_hash":"{target_state_hash}",
   "genesis_ledger": "..."
}
```

#### I am receiving errors from gsutil regarding missing precomputed blocks

When migrating last chunk of blocks from mainnet, there can be an issue for runs with
large `batch-size` argument inputs. As an optimization gsutil is trying to fetch as `block-size` amount of precomputed blocks.
However, when precomputed blocks bucket has not contain enough (= `block-size` amount) precomputed blocks gsutil may panic stopping migration process.
Our recommendation is to restart process with smaller number of `batch-size`. If you are running migration just after fork block is announced it is best
to have `--block-size` argument set up to 5.

#### How to start replayer migration from latest checkpoint

Instead of using Mainnet ledger as input config, provide the checkpoint for the `--input-config` parameter.