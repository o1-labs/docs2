---
title: Migrating Mainnet Archive to Berkeley Archive 
sidebar_label: Archive migration
hide_title: true
description: Steps to properly migrate archives from Mainnet to Berkeley.
keywords:
  - Berkeley
  - upgrade
  - archive migration
  - planning 
  - prerequisites
  - mina archive node
  - archive node
---

### Migration process

As mentioned in [Planning the Archive Migration](/berkeley-upgrade/planning-archive-migration), the mainnet migration can take up to a couple of days. 
Therefore, it is recommended to split migration into 3 stages:

- **Stage1:** Initial migration

- **Stage2:** Incremental migration

- **Stage3:** Remainder migration

Each stage has three migration phases:

- **Phase 1:** Copying data from mainnet database and precomputed blocks using the **berkeley_migration** app.

- **Phase 2:** Populating new berkeley tables using the **replayer app in migration mode**

- **Phase 3:** Additional validation for migrated database

At the end of entire cycle of migration you will recieve two databases:

- source database with original mainnet data
- migrated datbase with orginal mainnet data converted to berkeley schea

Review these phases and stages before you start the migration:

### Simplified approach

For user convenience we offer berkeley_migration.sh script. 
The script was created for users who either do not need to delve into the details of migration or whose environment does not require a special approach to migration

#### Stage 1: Initial migration

```
./scripts/archive/migration/berkeley_migration.sh  \ 
   initial \
   --genesis-ledger ledger.json \
   --source-db postgres://postgres:postgres@localhost:5432/source \
   --target-db postgres://postgres:postgres@localhost:5432/migrated \
   --blocks-bucket mina_network_block_data \
   --blocks-batch-size 50 \
   --network mainnet
```

where: 

`-g | --genesis-ledger`:  *path to genesis ledger file*

`-s | --source-db`: *connection string to database to be migrated*

`-t | --target-db`: *connection string to database which will hold migrated data*

`-b | --blocks-bucket`: *name of precomputed blocks bucket. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*

`-bs | --blocks-batch-size`: *number of precomputed blocks to be fetch at once from Gcloud. Bigger number like 1000 can help speed up migration process*

`-n | --network`: *network name when determining precomputed blocks. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*


This command should output migration-replayer-XXX.json which should be used in next run

#### Incremental migration

```
./scripts/archive/migration/berkeley_migration.sh \
   incremental \
   --genesis-ledger ledger.json \
   --source-db postgres://postgres:postgres@localhost:5432/source \
   --target-db postgres://postgres:postgres@localhost:5432/migrated \
   --blocks-bucket mina_network_block_data \
   --blocks-batch-size 50 \
   --network mainnet \
   --replayer-checkpoint migration-checkpoint.json
```

where:

`-r | --replayer-checkpoint`: *path to genesis ledger file*

`-g | --genesis-ledger`: *path to genesis ledger file*

`-s | --source-db`: *connection string to database to be migrated*

`-t | --target-db`: *connection string to database which will hold migrated data*

`-b | --blocks-bucket`: *name of precomputed blocks bucket. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*

`-bs | --blocks-batch-size`: *number of precomputed blocks to be fetch at once from Gcloud. Bigger number like 1000 can help speed up migration process*

`-n | --network`: *network name when determining precomputed blocks. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*
  
:info:

migration-checkpoint.json - is a last replayer checkpoint from initial run

#### Stage 3: Remainder migration

```
./scripts/archive/migration/berkeley_migration.sh \
   final \
   --genesis-ledger ledger.json \
   --source-db postgres://postgres:postgres@localhost:5432/source \
   --target-db postgres://postgres:postgres@localhost:5432/migrated \
   --blocks-bucket mina_network_block_data \
   --blocks-batch-size 50 \
   --network mainnet \
   --replayer-checkpoint migration-checkpoint.json \
   -fc fork-dump.json \
   -f fork-state-hash 
```

where: 

`-r | --replayer-checkpoint`: *path to replayer checkpoint file*

`-g | --genesis-ledger`: *path to genesis ledger file*

`-f | --fork-state-hash`: *fork state hash*

`-s | --source-db`: *connection string to database to be migrated*

`-t | --target-db`: *connection string to database which will hold migrated data*

`-b | --blocks-bucket`: *name of precomputed blocks bucket. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*

`-bs | --blocks-batch-size`: *number of precomputed blocks to be fetch at once from Gcloud. Bigger number like 1000 can help speed up migration process*

`-n | --network`: *network name when determining precomputed blocks. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*

`-fc | --fork-config`: *Fork-state config file is dump file in form of json containing fork block and ledger file. It should be provied by MF or O(1)Labs team after fork block is announced*
  

### Advanced approach

If simplified berkeley migraion script is for some reasons not suitable for you, there is always a possibility to run migration using berkeley_migration and replayer apps without
an interface which script provides. Please refer to below steps:

#### Stage 1: Initial migration

This stage is the very first one, which requires the initial `berkeley` schema only. It is a foundation for the next migration stage because it populates the migrated database and creates an initial checkpoint for further incremental migration.

- Inputs
   - Unmigrated mainnet database
   - Mainnet genesis ledger 
   - Empty target `berkeley` database (empty means with schema created but without any content)

- Outputs
   - Migrated `mainnet` database to `berkeley` format from genesis up to the last canonical block in orginal database
   - Replayer checkpoint, which can be used for incremental migration

##### Phase 1: Berkeley migration app run

```
mina-berkeley-migration \
   --batch-size 1000 \
   --config-file genesis_ledgers/mainnet.json \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string} \
   --blocks-bucket {bucket name} \
   --network "mainnet"
```
where: 
`--network` - network name when determining precomputed blocks. There is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`;



##### Phase 2: Replayer in migration mode run

Replayer config must contain the Mainnet ledger as the starting point. So first, you must prepare the replayer config file:

```
 jq '.ledger.accounts' genesis_ledger.json | jq  '{genesis_ledger: {accounts: .}}' > replayer_input_config.json
```

where:
   genesis_ledger.json is genesis file from which deamon bootstrap on particular network

Then:
```
 mina-replayer \
   --migration-mode \
   --archive-uri {migrated_connection_string} \
   --input-file replayer_input_config.json \
   --checkpoint-interval 10000
```

where:
 - `archive-uri` - connection string to archive datbase 
 - `output-file` - file which will hold ledger with auxiliary information like global slot and blockchain height which will be dumped on last block
 - `checkpoint-interval` - frequency of checkpoints file expressed in blocks count
 - `reference_replayer_input.json` is a file constructed out of network genesis ledger:
 
   ```
      jq '.ledger.accounts' genesis_ledger.json | jq  '{genesis_ledger: {accounts: .}}' > replayer_input_config.json
   ```

##### Phase 3: Validations

berkeley_migration_verifier app is capable of performing checks for both fully migrated and partially migrated database. 

```
 mina-berkeley-migration-verifier 
   pre-fork  \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string}  
```

where:
 - `mainnet-archive-uri` - connection string to original archive database 
 - `migrated-archive-uri` - connection string to migrated archive database 
 
#### Stage 2: Incremental migration

After the initial migration, the data is migrated data up to the last canonical block. However, `mainnet` data is progressing with new blocks that must also be migrated again and again until the fork block is announced. 

:info: incremental migration can and probably must be repeated couple of time until fork block is announced by O1 labs team.
You can ran incremental migration several times with new mainnet database and new replayer checkpoint file.

- Inputs
   - Newest mainnet database
   - Mainnet genesis ledger
   - Replayer checkpoint from last run 
   - Migrated berkeley database from initial migration 

- Outputs
   - Migrated mainnet database to berkeley up to last canonical block
   - Replayer checkpoint which can be used for next incremental migration

##### Phase 1: Berkeley migration app run

```
mina-berkeley-migration \
   --batch-size 1000 \
   --config-file genesis_ledgers/mainnet.json \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string} \
   --blocks-bucket {bucket name} \
   --network "mainnet"
```
where: 
`--network` - network name when determining precomputed blocks. There is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`;

##### Phase 2: Replayer in migration mode run

```
 mina-replayer \
   --migration-mode \
   --archive-uri {migrated_connection_string} \
   --input-file replayer-checkpoint-XXXXX.json \
   --checkpoint-interval 10000
```

where `replayer-checkpoint-XXXXX.json` - is last checkpoint generated from previous migration

Incremental migration can be run continuously on top of initial migration or last incremental until fork block is announced 

##### Phase 3: Validations

berkeley_migration_verifier app is capable of performing checks for both fully migrated and partially migrated database. 

```
 mina-berkeley-migration-verifier 
   pre-fork  \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string}  
```

where:
 - `mainnet-archive-uri` - connection string to original archive database 

Incremental migration can be run continuously on top of initial migration or last incremental until fork block is announced. 

#### Stage 3: Remainder migration

When the fork block is announced, you must tackle the remainder migration. This is the last migration run 
you need to perform. In this stage, we are closing migration cycle by last migration of remainder blocks between 
current last canonical block and fork block (which can be pending, so we don't need to wait 290 blocks until it would become canonical). 
Here you need to use `--fork-state-hash` as additional parameter to berkeley-migration app

- Inputs
   - Newest mainnet database
   - Mainnet genesis ledger
   - Replayer checkpoint from last run 
   - Migrated berkeley database from last run
   - Fork block state hash

- Outputs
   - Migrated mainnet database to berkeley up to fork point
   - Replayer checkpoint which can be used for replayer run on berkeley database


##### Phase 1: Berkeley migration app run

You might notice a decrease in `batch-size` for precomputed blocks as the tool might hit missing precomputed blocks problem if you fetch too many of them in a single batch while trying to migrate the newest blocks in the chain:

```
mina-berkeley-migration \
   --batch-size 2 \
   --config-file genesis_ledgers/mainnet.json \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string} \
   --blocks-bucket {bucket name} \
   --network "mainnet" \
   --fork-state-hash {fork-state-hash}
```
where: 
`--network` - network name when determining precomputed blocks. There is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`;
`--fork-state-hash` last migrated block which will be used as a fork point 

**Info** When running the **berkeley-migration** app with fork-state-hash, there is no requirement for the fork state block to be canonical.
The tool automatically converts all pending blocks in the subchain, including the fork block, to canonical blocks.

##### Phase 2: Replayer in migration mode run

```
mina-replayer \
   --migration-mode \
   --archive-uri {migrated_connection_string} \
   --input-file replayer-checkpoint-XXXXX.json \
   --checkpoint-interval 10000 \
   --output-file replayer_output.json 
```

where:
`replayer-checkpoint-XXXXX.json` - is last checkpoint generated from previous migration
`replayer-output.json` - will contain a very last checkpoint which can be used for berkeley replayer validation

It is important to save checkpoint which was dumped from replayer run, as it will be use in next migrations

##### Phase 3: Validations

berkeley_migration_verifier app is capable of performing checks for both fully migrated and partially migrated database. 

```
 mina-berkeley-migration-verifier 
   post-fork  \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string}  
   --fork-config-file String 
   --migrated-replayer-output Path
```

where:

`--fork-config-file` - Path to fork config file (alias: -fork-config-file)
`--mainnet-archive-uri` - Connection string to the mainnet archive database
`--migrated-archive-uri` - Connection string to the migrated archive database
`--migrated-replayer-output`  - Path to migrated replayer output


### Example steps using Mina Foundation data

1. Download and import archive dump:

   ```sh
   wget -c https://storage.googleapis.com/mina-archive-dumps/mainnet-archive-dump-2023-11-02_0000.sql.tar.gz

   tar -xf mainnet-archive-dump-2023-11-02_0000.sql.tar.gz 

   psql -U postgres -a -f mainnet-archive-dump-2023-11-02_0000.sql
   ```

2. Download migration software:

   ```sh
   CODENAME=bullseye
   CHANNEL=unstable
   # Berkeley nightly version
   VERSION=2.0.0berkeley-rc1-berkeley-c308efc-bullseye

   echo "deb [trusted=yes] http://packages.o1test.net $CODENAME $CHANNEL" | tee /etc/apt/sources.list.d/mina.list
   apt-get update
   apt-get install --allow-downgrades -y "mina-archive-berkeley-archive-migration=$VERSION"
   ```

3. Create empty database with schema only:

   ```sh
   wget https://raw.githubusercontent.com/MinaProtocol/mina/berkeley/src/app/archive/zkapp_tables.sql

   wget https://raw.githubusercontent.com/MinaProtocol/mina/berkeley/src/app/archive/create_schema.sql

   psql  -U postgres -c "CREATE DATABASE berkeley_migrated;"

   psql -U postgres -d berkeley_migrated -a -f create_schema.sql"
   ```

4. Stage 1: Initial migration

   4.a) Phase 1:

   ```sh
   mina-berkeley-migration.exe \
      --batch-size 2000 \
      --config-file /etc/mina/genesis_ledgers/mainnet.json \
      --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated \
      --migrated-archive-uri postgres://postgres:postgres@localhost/berkeley_migrated \
      --blocks-bucket mina_network_block_data \
      --network mainnet
   ```

   4.b) Phase 2:

   ```sh

   # mainnet.json is genesis file from which deamon bootstrap on particular network
   jq '.ledger.accounts' mainnet.json | jq  '{genesis_ledger: {accounts: .}}' > replayer_input_config.json

   mina-replayer \
      --migration-mode \
      --archive-uri postgres://postgres:postgres@localhost/ \
      --input-file replayer_config_input.json \
      --checkpoint-interval 100 \
      --checkpoint-file-prefix migration
   ```

5. Stage 2: Initial migration

   5.a) Phase 1:

   ```sh
   mina-berkeley-migration \
      --batch-size 2000 \
      --config-file /etc/mina/genesis_ledgers/mainnet.json \
      --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated \
      --migrated-archive-uri postgres://postgres:postgres@localhost/berkeley_migrated \
      --blocks-bucket mina_network_block_data \
      --network mainnet
   ```

   5.b) Phase 2:

   ```sh
   mina-replayer \
      --migration-mode \
      --archive-uri postgres://postgres:postgres@localhost/ \
      --input-file checkpoint-XXXX.json \
      --checkpoint-interval 100 \
      --checkpoint-file-prefix migration
   ```

5. Stage 2: Remainder migration

   5.a) Phase 1:

   ```sh
   mina-berkeley-migration \
      --batch-size 2000 
      --config-file /etc/mina/genesis_ledgers/mainnet.json \
      --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated \
      --migrated-archive-uri postgres://postgres:postgres@localhost/berkeley_migrated \
      --blocks-bucket mina_network_block_data \
      --network mainnet \
      --fork-state-hash "3NLdCBNrDseiDKvVj8rZ15k2oAUvx4XuCc8mzf6fL2CmqTJVVceM" 
   ```

   :warning: 3NLdCBNrDseiDKvVj8rZ15k2oAUvx4XuCc8mzf6fL2CmqTJVVceM - is an example random hash, please **do not user this hash** on the actual migration. Use the official hash as provided by Mina Foundation for the fork point.

   5.b) Phase 2:

   ```sh
   mina-replayer \
      --migration-mode \
      --archive-uri postgres://postgres:postgres@localhost/ \
      --input-file checkpoint-XXXX.json \
      --checkpoint-interval 100 \
      --checkpoint-file-prefix migration \
      --output-file migrated-checkpoint-at-fork-block.json
   ```


## How to verify a successful migration

o1Labs and the Mina Foundation make every effort to provide reliable tools of high quality. However, it is not possible to eliminate all errors and test all possible Mainnet archives variations. 

Follow this checklist to perform major versification's after migration to ensure data correctness. 

1. #### The Replayer from the Mainnet version generates the same ledger hash as the migrated

Ensure that replayer from Mainnet and berkeley generate the same ledger for the migrated and the Mainnet database. 

- To verify, start the Mainnet replayer with the same input config as Berkeley. 

- When you run replayer from Mainnet version on Mainnet, archive it with the `--output-file` option to generate a reference replayer output that can be compared with the migrated replayer output.

2. #### All transaction (user command and internal command) hashes are left intact

Verify that the `user_command` and `internal_command` tables have the Mainnet format of hashes. For example, `CkpZirFuoLVV...`.

3. #### Parent-child block relationship is preserved

Verify that a given block in the migrated archive has the same parent in the Mainnet archive (`state_hash` and `parent_hash` columns).

4. #### Account balances remain the same

Verify the same balance exists for a given block in Mainnet and migrated databases.

## Tips and tricks

We are aware that the migration process can be very long (a couple of days). Therefore, we encourage using cron jobs that migrate data incrementally. 
The cron job requires access to Google Cloud buckets (or other storage):

- A bucket to store migrated-so-far database dumps
- A bucket to store checkpoint files


:info: We are tightly coupled with Gcloud infrastructure at this moment due to precomputed block upload mechanism.
This is the reason why we are using also buckets for storing dumpa and checkpoint. However, it is not required to use Gcloud for other things than 
precomputed blocks.  

Before running the cron job, upload an initial database dump and an initial checkpoint file. 

To create the files, run these steps locally:

1. Download a Mainnet archive dump and load it into PostgreSQL.
2. Create a new, empty database using the new archive schema.
3. Run the berkeley-migration app against the Mainnet and new databases.
4. Run the replayer app in migration mode with the --checkpoint-interval set to some suitable value (perhaps 100) and start with the original Mainnet ledger in the input file.
5. Use pg_dump to dump the migrated database and upload it.
6. Upload the most recent checkpoint file.

The cron job performs the same steps in an automated fashion:

1. Pulls the latest Mainnet archive dump and loads it into PostgresQL.
2. Pulls the latest migrated database and loads it into PostgreSQL.
3. Pulls the latest checkpoint file.
4. Runs the berkeley-migration app against the two databases.
5. Runs the replayer app in migration mode using the downloaded checkpoint file; the checkpoint interval should be smaller (perhaps 50) because there are typically only 200 or so blocks in a day.
7. Uploads the migrated database.
8. Uploads the most recent checkpoint file.

Be sure to monitor the cron job in case there are errors.

Just before the Berkeley, migrate the last few blocks by running locally:

1. Download the Mainnet archive data directly from the k8s PostgreSQL node, not from the archive dump, and load it into PostgreSQL.
2. Download the most recent migrated database and load it into PostgresQL.
3. Download the most recent checkpoint file.
4. Run the berkeley-migration app against the two databases.
5. Run the replayer app in migration mode using the most recent checkpoint file.

It is worthwhile to perform these last steps as a dry run to make sure all goes well. You can run these steps as many times as needed.

### Known migration problems

#### Berkeley migration app is consuming all of my resources

When running a full migration, you can stumble on memory leaks that prevent you from cleanly performing the migration in one pass. A machine with 64 GB of RAM can be frozen after ~40k migrated blocks. Each 200 blocks inserted into the database increases the memory leak by 4â€“10 MB.

A potential workaround is to split migration into smaller parts using cron jobs or automation scripts.

Related Github issues:
- [#13714](https://github.com/MinaProtocol/mina/issues/13714)
- [#14924](https://github.com/MinaProtocol/mina/issues/14924)

## FAQ

#### Migrated database is missing orphaned blocks

By design, Berkeley migration omits orphaned blocks and, by default, migrates only canonical ( and pending if setup correctly ) blocks.

#### Replayer in migration mode overrides my old checkpoints

Replayer by default dumps the checkpoint to the current folder. All checkpoint files have a similar format:

`replayer-checkpoint-{number}.json.`

To modify the output folder and prefix, you can use the `--checkpoint-output-folder` and `--checkpoint-file-prefix` parameters to prevent override of old checkpoints.

#### Receipt chain hashes mismatch between Mainnet and Berkeley schemas

Receipt chain hashes are expressed in a new format in the Berkeley version. They contain the same value, though.

#### Replayer in migration mode exits the process in the middle of the run

Most likely, there are some missing blocks in the Mainnet database. Ensure that you patched the Mainnet archive before the migration process. Alternatively, you can provide `--continue-on-error` parameter.

#### How to migrate Mainnet pending blocks

In the first phase of migration use the `--end-global-slot` parameter. 

In the second phase of migration, add property `target_epoch_ledgers_state_hash` with the expected `state_hash` value:

```json
{
   "target_epoch_ledgers_state_hash":"{target_state_hash}",
   "genesis_ledger": "..."
}
```

#### I am receiving errors from gsutil regarding missing precomputed blocks

When migrating last chunk of blocks from mainnet, there can be an issue for runs with
large `batch-size` argument inputs. As an optimization gsutil is trying to fetch as `block-size` amount of precomputed blocks.
However, when precomputed blocks bucket has not contain enough (= `block-size` amount) precomputed blocks gsutil may panic stopping migration process.
Our recommendation is to restart process with smaller number of `batch-size`. If you are running migration just after fork block is announced it is best
to have `--block-size` argument set up to 5.
